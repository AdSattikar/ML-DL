{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd28ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af8b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a77062f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068332</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022688</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005670 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6  \n",
       "0 -0.002592  0.019907 -0.017646  \n",
       "1 -0.039493 -0.068332 -0.092204  \n",
       "2 -0.002592  0.002861 -0.025930  \n",
       "3  0.034309  0.022688 -0.009362  \n",
       "4 -0.002592 -0.031988 -0.046641  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create data frame for the given values\n",
    "df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c55288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   age     442 non-null    float64\n",
      " 1   sex     442 non-null    float64\n",
      " 2   bmi     442 non-null    float64\n",
      " 3   bp      442 non-null    float64\n",
      " 4   s1      442 non-null    float64\n",
      " 5   s2      442 non-null    float64\n",
      " 6   s3      442 non-null    float64\n",
      " 7   s4      442 non-null    float64\n",
      " 8   s5      442 non-null    float64\n",
      " 9   s6      442 non-null    float64\n",
      "dtypes: float64(10)\n",
      "memory usage: 34.7 KB\n"
     ]
    }
   ],
   "source": [
    "#This will tell us the total number of non null observations present including the total number of entries. Once number of entries isnâ€™t equal to number of non null observations, we can begin to suspect missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3db1075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age    0\n",
       "sex    0\n",
       "bmi    0\n",
       "bp     0\n",
       "s1     0\n",
       "s2     0\n",
       "s3     0\n",
       "s4     0\n",
       "s5     0\n",
       "s6     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This will tell us the total number of NaN in or data.\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "749e668c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP array:\n",
      " [[ 0.02]\n",
      " [-0.03]\n",
      " [-0.01]\n",
      " [-0.04]\n",
      " [ 0.02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "array = df.values\n",
    "bparr = array[0:5,3:4]\n",
    "print(\"BP array:\\n\",bparr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f757ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdlarr = array[0:5,6:7]\n",
    "print(\"HDL array: \\n\",hdlarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2352999",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "rescaledBP = scaler.fit_transform(bparr) \n",
    "np.set_printoptions(precision=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "135c99eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaled HDL:\n",
      " [[-0.91]\n",
      " [ 1.56]\n",
      " [-0.68]\n",
      " [-0.76]\n",
      " [ 0.17]]\n"
     ]
    }
   ],
   "source": [
    "rescaledhdl = scaler.fit_transform(hdlarr) \n",
    "np.set_printoptions(precision=2) \n",
    "print(\"Rescaled HDL:\\n\",rescaledhdl[0:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daa3d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BP test:\n",
      " [[-0.34]\n",
      " [ 0.46]\n",
      " [-0.26]\n",
      " [ 1.67]\n",
      " [-0.05]\n",
      " [-0.55]\n",
      " [ 0.32]\n",
      " [ 0.46]\n",
      " [-1.2 ]\n",
      " [-0.41]]\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(rescaledBP,rescaledhdl,test_size=0.3,random_state=42)\n",
    "print(\"BP test:\\n\",x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac613376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDL test:\n",
      " [[ 0.4 ]\n",
      " [ 0.02]\n",
      " [ 1.18]\n",
      " [-1.61]\n",
      " [-0.14]\n",
      " [ 1.49]\n",
      " [-0.45]\n",
      " [ 0.02]\n",
      " [-0.14]\n",
      " [ 0.4 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"HDL test:\\n\",y_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af5b3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(rescaledBP,rescaledhdl,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e669441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict train: \n",
      " [-0.2  -0.2  -0.09 -0.2   0.11  0.18 -0.11  0.08 -0.13  0.07]\n",
      "Predict test: \n",
      " [ 0.11 -0.07  0.1  -0.19  0.07  0.1  -0.03 -0.07  0.11  0.11]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10,10), activation='relu', max_iter=1000)\n",
    "mlp.fit(x_train,y_train)\n",
    "\n",
    "predict_train = mlp.predict(x_train)\n",
    "predict_test = mlp.predict(x_test)\n",
    "\n",
    "print(\"Predict train: \\n\",predict_train[0:10])\n",
    "print(\"Predict test: \\n\",predict_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc872de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error for training samples  0.7570299931206426\n",
      "Mean absolute error for testing samples  0.7903444141844985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean absolute error for training samples \",mean_absolute_error(predict_train,y_train))\n",
    "print(\"Mean absolute error for testing samples \",mean_absolute_error(predict_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb3abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error for training samples  0.9546008281348414\n",
      "Mean squared error for testing samples  0.9452076921968656\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean squared error for training samples \",mean_squared_error(predict_train,y_train))\n",
    "print(\"Mean squared error for testing samples \",mean_squared_error(predict_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2771bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score for training samples -37.286606902149835\n",
      "r2 score for testing samples -32.8990211141563\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"r2 score for training samples\",r2_score(predict_train,y_train))\n",
    "print(\"r2 score for testing samples\",r2_score(predict_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33392cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(rescaledBP,rescaledhdl,test_size=0.50,random_state=42)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10,10), activation='relu', max_iter=1000)\n",
    "mlp.fit(x_train,y_train)\n",
    "predict_train = mlp.predict(x_train)\n",
    "predict_test = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09bcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error for training samples  0.7786924365571825\n",
      "Mean absolute error for testing samples  0.7736004453846547\n",
      "Mean squared error for training samples  1.0140401257801852\n",
      "Mean squared error for testing samples  0.9197977682787534\n",
      "r2 score for training samples -31.82549936095471\n",
      "r2 score for testing samples -29.638265952071233\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean absolute error for training samples \",mean_absolute_error(predict_train,y_train))\n",
    "print(\"Mean absolute error for testing samples \",mean_absolute_error(predict_test, y_test))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean squared error for training samples \",mean_squared_error(predict_train,y_train))\n",
    "print(\"Mean squared error for testing samples \",mean_squared_error(predict_test, y_test))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"r2 score for training samples\",r2_score(predict_train,y_train))\n",
    "print(\"r2 score for testing samples\",r2_score(predict_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf176504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1607: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(rescaledBP,rescaledhdl,test_size=0.75,random_state=42)\n",
    "mlp = MLPRegressor(hidden_layer_sizes=(10,10,10), activation='relu',max_iter=1000)\n",
    "mlp.fit(x_train,y_train)\n",
    "predict_train = mlp.predict(x_train)\n",
    "predict_test = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad5a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error for training samples  0.7445598563208751\n",
      "Mean absolute error for testing samples  0.8468949093357337\n",
      "Mean squared error for training samples  0.9297458056467313\n",
      "Mean squared error for testing samples  1.0900236688007257\n",
      "r2 score for training samples -5.752192553058887\n",
      "r2 score for testing samples -4.898403147742305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "print(\"Mean absolute error for training samples \",mean_absolute_error(predict_train,y_train))\n",
    "print(\"Mean absolute error for testing samples \",mean_absolute_error(predict_test, y_test))\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Mean squared error for training samples \",mean_squared_error(predict_train,y_train))\n",
    "print(\"Mean squared error for testing samples \",mean_squared_error(predict_test, y_test))\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"r2 score for training samples\",r2_score(predict_train,y_train))\n",
    "print(\"r2 score for testing samples\",r2_score(predict_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34d5cb",
   "metadata": {},
   "source": [
    "The most optimal sample is the 50% testing samples where the errors are minimum when compared to 30% and 75% \n",
    "samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4737b67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
